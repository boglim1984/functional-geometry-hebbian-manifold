# Functional Geometry in Deep Neural Networks

## Overview

This repository documents an experimental research arc investigating learned functional geometry in deep neural networks. The project demonstrates the existence, causality, and system-level effects of geometric structure that emerges during training, explores its implications for model compression, interpretability, and plasticity, and defines functional geometry as structure induced by cosine similarity between neuron activation vectors.

Geometric proximity predicts functional interchangeability under intervention. Motivated by the need for safer, interpretable model compression and causal validation of learned representations. The term â€˜Hebbianâ€™ is used descriptively to denote geometry emerging from correlated activations during training, not a specific synaptic update rule.

## Key Measured Results (Summary)

- Single-pair biopsy: ~14Ã— sensitivity separation (Far vs Near merges)
- Batch biopsy: ~5Ã— mean |Î”Loss| separation (Near vs Far cohorts)
- Mass consolidation: ~1.8Ã— stability advantage (geometry-guided vs random)

## ğŸ“– How to Read This Repository

New readers should start with [docs/how_to_read.md](docs/how_to_read.md) for a concise orientation guide to the repository structure, evidence flow, and experimental phases.


## Core Hypothesis

Neural networks learn functional geometryâ€”structured manifolds in activation space that encode redundancy, stiffness, and causal relationships between neurons. This geometry can be:
- **Mapped** through dimensionality reduction and clustering
- **Validated** through targeted surgical interventions
- **Exploited** for safe model consolidation
- **Perturbed** to study plasticity dynamics

[![Layer 4 trained manifold (ResNet18)](artifacts/figures/phase1_trained_layer4.jpg)](artifacts/figures/phase1_trained_layer4.jpg)

*Figure: 3D projection of the Layer 4 activation correlation manifold for a trained ResNet18.  
This image is a visualization aid only; canonical data is provided via the PLY artifacts in `artifacts/ply/`.*

## Experimental Phases

Canonical manifold data is stored as PLY artifacts in `artifacts/ply/` (Git LFS). 
If preview or download fails, clone the repository and run `git lfs pull`.

### Phase I: Neuro-Cartography (Manifold Discovery)

**Objective**: Map the functional geometry of trained networks by analyzing activation patterns across layers.

**Primary Evidence (Colab)**:
- `01_neuro_cartography.ipynb` ([Link](https://colab.research.google.com/drive/1Fq1l2yQtmzHF7zrIWcXd_1iyKWYtFNm6?usp=drive_link))
- `02_untrained_baseline_manifold.ipynb` ([Link](https://colab.research.google.com/drive/1aJIFXcehXMtid97zwfKfozseJt2A9L9Q?usp=drive_link))
- `03_pixel_shuffle_control.ipynb` ([Link](https://colab.research.google.com/drive/19qUlvA5l7vMswTg0psYmb-Iw6IEFboEs?usp=drive_link))

**Phase I Visual Previews**

- **01_neuro_cartography.ipynb**  
  Colab: https://colab.research.google.com/drive/1Fq1l2yQtmzHF7zrIWcXd_1iyKWYtFNm6  
  Preview: [phase1_trained_layer4.jpg](artifacts/figures/phase1_trained_layer4.jpg)

- **02_untrained_baseline_manifold.ipynb**  
  Colab: https://colab.research.google.com/drive/1aJIFXcehXMtid97zwfKfozseJt2A9L9Q  
  Preview: [phase1_untrained_layer4.jpg](artifacts/figures/phase1_untrained_layer4.jpg)

- **03_pixel_shuffle_control.ipynb**  
  Colab: https://colab.research.google.com/drive/19qUlvA5l7vMswTg0psYmb-Iw6IEFboEs  
  Preview: [phase2_pixelshuffle_layer4.jpg](artifacts/figures/phase2_pixelshuffle_layer4.jpg)

Images are illustrative only; canonical measurements are derived from the linked notebooks.

### Phase II: Biopsy (Causal Testing)

**Objective**: Validate that geometric proximity predicts functional redundancy through targeted neuron removal.

**Primary Evidence (Colab)**:
- **04_failed_biopsy.ipynb** & **05_neuro_surgeon_biopsy_v2.ipynb**  
  Colab: https://colab.research.google.com/drive/110sO1CQ5d8Worg3PrXJY2nmGgRtbdR5M  
  (The former documents a failed configuration; the latter documents the corrected protocol.)


### Phase III: Mass Consolidation

**Objective**: Scale geometry-guided compression to system level.

**Primary Evidence (Colab)**:
- **06_neuro_surgeon_batch_biopsy.ipynb**  
  Colab: https://colab.research.google.com/drive/1bxQ-ZOA6lep-b2QhyvM71dj5zt1YI7vc

- **07_neuro_surgeon_mass_consolidation.ipynb**  
  Colab: https://colab.research.google.com/drive/1VVuKh1WrFA_y182QiERAeHuI7zSVFPiJ

**Status**: Statistical validation COMPLETE.

### Phase IV: Sleep / Plasticity Test

**Objective**: Investigate whether geometric perturbation affects learning dynamics.

**Primary Evidence (Colab)**:
- **08_neuro_sleep.ipynb**  
  Colab: https://colab.research.google.com/drive/110sO1CQ5d8Worg3PrXJY2nmGgRtbdR5M


**Status**: COMPLETE (Negative result verified).


## Empirical Results (Measured)

| Experiment | Metric | Result |
|-----------|--------|--------|
| Single-Pair Biopsy | Sensitivity ratio (Far Ã· Near) | â‰ˆ 14Ã— |
| Batch Biopsy (N=50, Near) | Mean \|Î”Loss\| | 0.0119 Â± 0.0098 |
| Batch Biopsy (N=50, Far) | Mean \|Î”Loss\| | 0.0594 Â± 0.1377 |
| Mass Consolidation (50 pairs, Geometry-guided) | Î”Loss | âˆ’0.376 |
| Mass Consolidation (50 pairs, Random) | Î”Loss | âˆ’0.681 |
| Plasticity Test (5 epochs, Geometry-guided) | Peak accuracy | 84.7% |
| Plasticity Test (5 epochs, Random) | Peak accuracy | 86.8% |

"All results are measured directly from intervention experiments and reported as loss or accuracy deltas relative to identical baselines. Negative Î”Loss values indicate improved alignment due to head mismatch and should be interpreted by magnitude, not sign."

## Key Results (Verified)

- Geometry predicts redundancy: neuron-pair proximity in activation space predicts functional interchangeability under intervention.
- Geometry-guided consolidation is more stable than random merging at scale.

## Key Findings

1. **Functional geometry exists**: Neurons organize into structured manifolds in activation space
2. **Geometry predicts redundancy**: Proximal neurons in geometric space exhibit functional interchangeability
3. **Local merges are safe**: Consolidating nearby neurons preserves performance
4. **Distant merges destabilize**: Merging geometrically distant neurons degrades function
5. **Geometry-guided consolidation works**: Compression informed by manifold structure outperforms naive approaches
6. **Geometry encodes stability, not learning speed**: Geometric consolidation does not significantly improve learning speed under transfer learning; benefits appear primarily in stability, not plasticity.

These findings have been re-evaluated under an upgraded traversal probe that reduces probe-induced artifacts (see Instrument Transition below).

## What This Is / Is Not

**This is**:
- A mechanistic interpretability study
- An exploration of compression priors
- A demonstration of causal validation methods
- An archive of experimental results with controls

**This is not**:
- A claim about biological neural networks
- A general theory of deep learning
- A production-ready compression method
- A complete explanation of network function

## Instrument Transition â€” Walker Probe Upgrade

INSTRUMENT TRANSITION NOTE â€” WALKER UPGRADE

This project transitions from Instrument Iâ‚€ (baseline random walker) to Instrument Iâ‚ (metric-aware + short-memory walker).

Scope of change:
- The underlying model, training procedure, dataset, and representations remain unchanged.
- No learning, optimization, or parameter updates are introduced.
- The upgrade applies only to the traversal instrument used to probe latent-space structure.

Rationale:
Instrument Iâ‚€ exhibited probe-induced artifacts, including local looping, seed sensitivity, and isotropic traversal assumptions that reduced measurement fidelity. Instrument Iâ‚ improves traversal fidelity by adapting to local geometric variance and suppressing redundant revisits, without encoding task-specific priors or hypotheses.

Continuity of hypothesis:
All prior hypotheses regarding latent structure are preserved unchanged. Instrument Iâ‚ is strictly downstream and monotonic in epistemic power: it may reduce false positives or clarify structure, but cannot introduce structure not already present in the representation.

Interpretation policy:
Results obtained under Instrument Iâ‚ are treated as higher-resolution evaluations of the same hypotheses tested under Instrument Iâ‚€. Agreement strengthens confidence; disagreement is interpreted as probe correction rather than hypothesis failure.

Status:
Instrument Iâ‚€ is retained as a baseline reference. Instrument Iâ‚ is adopted as the primary probe going forward.

### Latest Probe Study (Colab)

This study evaluates the upgraded probe on a frozen ResNet embedding space.

- **Metric-Aware Walker Probe Study**: https://colab.research.google.com/drive/1zGZH1utq38y4G9RjYEchbuF2ObB_WDTX?usp=sharing

### Probe Results â€” Visual Summary

â€œThese figures summarize the behavioral differences between the baseline random walker (Instrument Iâ‚€) and the upgraded metric-aware + short-memory walker (Instrument Iâ‚) when probing a frozen ResNet embedding space. The results illustrate reduced probe-induced looping, increased trajectory diversity, and more coherent traversal under the upgraded instrument. No model parameters or representations are modified.â€

![Trajectory diversity and loop frequency comparison between baseline and upgraded walkers](artifacts/figures/walker_probe_diversity_and_loops.png)
â€œTrajectory diversity (left) and loop frequency (right) across multiple runs, showing higher coverage and reduced revisitation under the upgraded probe.â€

![PCA projection of walker trajectories comparing baseline and upgraded probes](artifacts/figures/walker_probe_pca_trajectory_comparison.png)
â€œRepresentative walker trajectories projected via PCA, illustrating reduced jitter and more directed traversal under the upgraded probe.â€

This study does not modify prior hypotheses, models, or training.

### Experiment 1 â€” Highway Convergence Test (Structural Anisotropy)

**Objective**

Evaluate whether the upgraded traversal probe (Instrument Iâ‚), which is metric-aware and suppresses short-term revisits, reveals global structural anisotropy in the latent space by inducing convergence of independent walkers starting from distant locations.

This experiment tests for the presence of shared â€œtransit corridorsâ€ or â€œhighwaysâ€ in the embedding geometry that are not detectable under isotropic random sampling.

**Experimental Setup**

- Model: Frozen ResNet18 encoder
- Dataset: CIFAR-10 (test split, subset)
- Representation: L2-normalized embedding space
- Graph: k-NN graph over embeddings
- Instruments:
  - Iâ‚€: Baseline isotropic, memoryless random walker
  - Iâ‚: Metric-aware, short-memory walker biased toward local variance
- Protocol:
  - Select 50 pairs of starting nodes separated by large cosine distance
  - Run independent walkers from each start for a fixed number of steps
  - Measure convergence using Jaccard overlap of visited node sets

**Quantitative Results**

- Instrument Iâ‚€ (baseline):
  - Mean overlap â‰ˆ 0.020
- Instrument Iâ‚ (upgraded):
  - Mean overlap â‰ˆ 0.038
- Convergence factor (Iâ‚ / Iâ‚€):
  - â‰ˆ 1.9Ã—

The upgraded probe consistently produces higher overlap between independent walkers than the isotropic baseline, indicating weak but systematic convergence.

**Figure 1 â€” Convergence Statistics**

![Convergence boxplot comparing baseline and upgraded walkers](artifacts/figures/experiment1_convergence_boxplot.png)

Independent walkers under Instrument Iâ‚ exhibit higher and more frequent overlap than under Instrument Iâ‚€, whose overlap remains near chance with occasional outliers.

**Qualitative Visualization**

To contextualize the quantitative results, a representative pair of Iâ‚ trajectories is projected into two dimensions using PCA.

**Figure 2 â€” Qualitative Highway Convergence (PCA Projection)**

![PCA visualization of independent Iâ‚ walker convergence](artifacts/figures/experiment1_pca_highway_convergence.png)

Although the walkers do not follow identical paths, they bend toward shared regions of the latent space, consistent with the presence of sparse, anisotropic transit corridors rather than a single global attractor.

**Interpretation**

- The latent space is not isotropic: flow is constrained along preferred directions.
- High-variance regions form a weak but real connective skeleton (â€œhighwaysâ€).
- The effect is reproducible across random seeds and absent under the baseline probe.
- No semantic interpretation or class structure is assumed or inferred.

This experiment demonstrates that improved probe fidelity reveals global geometric constraints that are invisible under random diffusion.

### Experiment 2 â€” Densityâ€“Occupancy Correlation (Topological Positioning)

**Colab Notebook:**  
https://colab.research.google.com/drive/15keQSvznJ6HUIk13WlWuGyxElHO1iiLA

**Objective**  
This experiment characterizes the topological location of the high-variance traversal pathways (â€œhighwaysâ€) identified in Experiment 1. Specifically, it tests whether variance-biased probe dynamics preferentially occupy high-density regions (cluster cores / prototypes) or low-density regions (boundaries / transitions) of the latent space.

**Method**  
A static local density metric was computed for each node in the latent-space k-NN graph, defined as the inverse mean cosine distance to its nearest neighbors. Dynamic occupancy was measured by aggregating visit frequencies from long-run probe trajectories. Correlation between static density and dynamic occupancy was quantified using Spearman rank correlation. Instrument Iâ‚€ (baseline isotropic walker) served as a null control, while Instrument Iâ‚ (variance-biased, short-memory walker) represented the upgraded probe.

**Results**  
Instrument Iâ‚€ exhibited a strong positive correlation between density and occupancy (Spearman r = 0.799), consistent with isotropic diffusion favoring dense hubs by chance. Instrument Iâ‚ exhibited an even stronger positive correlation (Spearman r = 0.824), with a measurable increase relative to Iâ‚€ (Î”r â‰ˆ +0.025). This shift indicates that the variance-biased probe preferentially inhabits dense regions of the manifold beyond what is expected from isotropic traversal alone.

**Interpretation**  
The results indicate that the high-variance â€œhighwaysâ€ identified in Experiment 1 are embedded within dense regions of the latent space rather than along sparse boundaries. High feature variance in this representation corresponds to internal structure within cluster cores (â€œbackbonesâ€), rather than instability or class-transition zones (â€œfault linesâ€). This supports the interpretation that the representation concentrates its most sensitive and information-rich directions inside stable, highly populated regions of the manifold.

**Figure**  
*Densityâ€“Occupancy Relationship for Instrument Iâ‚€ and Instrument Iâ‚.*  
The hexbin plots visualize static node density versus dynamic occupancy probability. Instrument Iâ‚ shows a strengthened positive coupling relative to Iâ‚€, indicating preferential traversal of dense regions.

![Densityâ€“Occupancy Correlation](artifacts/figures/phase2_density_occupancy_correlation.png)

**Status**  
Experiment 2 confirms that variance-driven traversal pathways correspond to dense latent backbones rather than boundary regions. This result constrains the geometry of the representation and motivates subsequent experiments probing internal directional coherence within dense cores.

### Experiment 3 â€” Vector Field Alignment (Local Linear Geometry)

**Colab Notebook:**  
https://colab.research.google.com/drive/1aQNVJru_8MLIA3wjxUEHmAFs2LmAzeco?usp=sharing

**Objective**  
Determine whether the dense â€œbackbonesâ€ identified in Experiments 1â€“2 are locally linear (fibrous) or internally isotropic (blob-like).

**Method**  
For each node in the latent k-NN graph, a local tangent direction was estimated using the first principal component (PC1) of its neighborhood.  
Both Instrument Iâ‚€ (isotropic random walker) and Instrument Iâ‚ (variance-biased, short-memory walker) were run over the graph.  
For every traversal step, the cosine alignment between the step displacement and the local tangent was measured.  
Distributions of alignment scores were compared using a Mannâ€“Whitney U test.

**Results**  
- Mean alignment (Iâ‚€): â‰ˆ 0.29  
- Mean alignment (Iâ‚): â‰ˆ 0.29  
- Alignment factor (Iâ‚ / Iâ‚€): â‰ˆ 1.01Ã—  
- Difference not statistically significant (p > 0.05)

**Interpretation**  
Although Instrument Iâ‚ reliably converges into dense, high-variance regions of the latent space, traversal within these regions does not exhibit preferential alignment with local tangent directions.  
This indicates that the dense backbones identified in earlier experiments are internally isotropic rather than composed of coherent low-dimensional fibers.

**Conclusion**  
ResNet18 latent representations exhibit structured attractor regions that bias global traversal, but these regions do not decompose into locally linear manifolds at the scale tested.  
The representation clusters variation into dense cores without linearizing it into disentangled axes.

**Figure**  
*Distribution of Local Tangent Alignment (Cosine).*  
The near-identical distributions indicate isotropic diffusion within dense latent backbones.

![Vector Field Alignment](artifacts/figures/experiment_3_vector_field_alignment.png)

## Phase I Summary â€” Latent Geometry Probing

This project investigates the geometric structure of neural network latent representations using probe-based traversal instruments, without modifying the model, training procedure, dataset, or supervision.

All experiments were conducted on a frozen ResNet18 encoder. Structure is inferred exclusively through downstream traversal behavior on a k-nearest-neighbor graph of latent embeddings.

### Instrumentation

Two traversal instruments were used:

- **Instrument Iâ‚€ (Baseline Walker):**  
  An isotropic, memoryless random walker serving as a null probe.

- **Instrument Iâ‚ (Upgraded Walker):**  
  A metric-aware, short-memory walker biased toward regions of high local feature variance, designed to reduce probe-induced artifacts while remaining strictly downstream and non-creative.

Instrument Iâ‚€ is retained as a baseline reference; Instrument Iâ‚ is adopted as the primary probe.

### Phase I Findings

Across three experiments, the following conclusions were established:

1. **Structural Anisotropy (Experiment 1):**  
   Independent Iâ‚ walkers converge into shared transit corridors, demonstrating non-random, anisotropic structure in the latent space.

2. **Topological Positioning (Experiment 2):**  
   Variance-biased traversal preferentially inhabits high-density regions. The identified â€œhighwaysâ€ lie within dense cluster cores (â€œbackbonesâ€), not sparse boundaries or transition zones.

3. **Local Geometry (Experiment 3):**  
   Despite global anisotropy and dense attractors, traversal within these backbones is locally isotropic. No significant alignment with local tangent directions was observed.

### Consolidated Interpretation

ResNet18 latent representations contain structured, high-density attractor regions that bias global traversal, but these regions do not decompose into locally linear or fibrous manifolds at the scale tested.  
The representation clusters variation into dense cores without linearizing it into disentangled axes.

### Scope and Limits

- No labels, supervision, or downstream tasks were used.
- No model parameters were updated.
- All conclusions are geometric and probe-dependent.
- Results characterize structure, not semantics or performance.

Phase I establishes a controlled geometric baseline for subsequent comparative or longitudinal studies.

## Phase II â€” Future Directions (Placeholder)

Phase II will extend the geometric probing framework established in Phase I to comparative, longitudinal, or scale-dependent settings.

Potential directions include (non-exhaustive):
- Cross-architecture comparisons (e.g., CNNs vs. transformers)
- Layer-wise or depth-wise geometric analysis
- Training-time evolution of latent geometry
- Scale-dependent or multi-resolution probing
- Controlled synthetic manifolds for validation

No Phase II experiments have been finalized or executed at this stage.  
This section serves solely as a placeholder to preserve structural continuity of the project.

## Repository Structure

```
/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ executive_summary.md               # High-level conclusions
â”œâ”€â”€ notebooks/                         # Primary Colab Record (stubs)
â”‚   â”œâ”€â”€ 01_neuro_cartography.ipynb
â”‚   â”œâ”€â”€ 02_untrained_baseline_manifold.ipynb
â”‚   â”œâ”€â”€ 03_pixel_shuffle_control.ipynb
â”‚   â”œâ”€â”€ 04_failed_biopsy.ipynb
â”‚   â”œâ”€â”€ 05_neuro_surgeon_biopsy_v2.ipynb
â”‚   â”œâ”€â”€ 06_neuro_surgeon_batch_biopsy.ipynb
â”‚   â”œâ”€â”€ 07_neuro_surgeon_mass_consolidation.ipynb
â”‚   â”œâ”€â”€ 08_neuro_sleep.ipynb
â”‚   â”œâ”€â”€ 09_metric_aware_walker_probe.ipynb
â”‚   â”œâ”€â”€ 10_density_occupancy_correlation.ipynb
â”‚   â””â”€â”€ 11_vector_field_alignment.ipynb
â”œâ”€â”€ scripts/                           # Supporting Scripts
â”‚   â”œâ”€â”€ neuro_surgeon_batch.py
â”‚   â””â”€â”€ neuro_sleep.py
â”œâ”€â”€ artifacts/                         # Generated outputs
â”‚   â”œâ”€â”€ ply/                          # 3D manifold exports
â”‚   â””â”€â”€ figures/                      # Plots and visualizations
â”œâ”€â”€ docs/                              # Additional documentation
â”‚   â””â”€â”€ research_notes.md
â””â”€â”€ LICENSE                            # MIT License
```

## Status & Future Work

**Completed**:
- Phase I: Manifold discovery and visualization
- Phase II: Causal validation through targeted ablation
- Phase III: System-scale consolidation
- Phase IV: Plasticity and relearning dynamics (Negative result verified)

**Future Work**:
- Cross-architecture validation
- Theoretical formalization

## Reproducibility / Environment

For consistent results, please use the environment specified in `requirements.txt`.

```bash
pip install -r requirements.txt
```


## Citation

If you use this work, please cite:

```
@misc{functional-geometry-2026,
  title={Functional Geometry in Deep Neural Networks},
  author={boglim},
  year={2026},
  url={https://github.com/boglim1984/functional-geometry-hebbian-manifold}
}
```

## Repository Status

This repository reflects a completed experimental arc with ongoing consolidation and documentation.

Recent commits focus on:
- aligning notebook coverage with documented phases
- standardizing artifact naming
- improving reader orientation and traceability

The core experimental results are stable as of this release.

## License

MIT License - see [LICENSE](LICENSE) for details.
